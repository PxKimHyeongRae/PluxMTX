# MediaMTX 추가 성능 최적화 계획

## 현재 상태

### 이미 적용된 최적화
- ✅ NACK 인터셉터 제거: -75% 메모리, -37% CPU
- ✅ mDNS 비활성화: -36% 메모리 추가, -19% CPU 추가
- ✅ **총 개선**: -84.3% 메모리, -43% CPU

### 현재 성능 (프로파일 기준)
- **힙 메모리**: 28.30 MB
- **고루틴**: 2,562개
- **CPU 샘플 비율**: 21.5% (180초 중 38.75초)

### 남은 CPU 소비처
1. syscall.Syscall6: 13.90s (35.87%) - 네트워크 I/O
2. SRTP 암호화: ~3.5s (9%) - SHA1 + AES
3. 런타임 오버헤드: ~3s (7.7%) - GC, 스케줄링
4. 메모리 할당: ~1.5s (3.9%)

---

## 추가 최적화 계획

### 최적화 1: RTCP 간격 조정 ⭐ (우선순위: 높음)

#### 현재 상태
```go
// internal/protocols/webrtc/outgoing_track.go
Period: 1 * time.Second  // 1초마다 RTCP 전송
```

#### 문제점
- RTCP 리포트가 너무 자주 전송됨
- 불필요한 CPU 사용 및 네트워크 대역폭 소비

#### 최적화 방법
```go
Period: 3 * time.Second  // 3초로 변경
```

#### 예상 효과
- **CPU**: -3~5% 절감
- **네트워크**: RTCP 트래픽 66% 감소
- **품질 영향**: 없음 (3초도 충분히 빠름)

#### 구현 난이도: ⭐ (매우 쉬움)
- 한 줄 수정
- 위험도: 낮음

#### 파일 위치
- `internal/protocols/webrtc/outgoing_track.go`

---

### 최적화 2: 버퍼 풀 사용 ⭐⭐ (우선순위: 중간)

#### 현재 상태
```
runtime.mallocgc: ~1.5s (3.9%)
```
- RTP 패킷마다 새로운 버퍼 할당
- GC 압력 증가

#### 문제점
- 메모리 할당/해제 오버헤드
- GC가 1.47s (3.8%) CPU 사용

#### 최적화 방법
`sync.Pool`을 사용하여 버퍼 재사용:

```go
// 전역 버퍼 풀
var rtpBufferPool = sync.Pool{
    New: func() interface{} {
        return make([]byte, 1500) // MTU 크기
    },
}

// 사용
buf := rtpBufferPool.Get().([]byte)
defer rtpBufferPool.Put(buf)
```

#### 적용 대상
1. RTP 패킷 버퍼
2. RTSP 읽기 버퍼
3. 암호화 임시 버퍼

#### 예상 효과
- **CPU**: -2~3% 절감 (GC 감소)
- **메모리**: 할당 횟수 감소
- **GC 중단 시간**: 감소

#### 구현 난이도: ⭐⭐ (중간)
- 여러 파일 수정 필요
- 버퍼 크기 관리 주의
- 위험도: 중간 (버퍼 재사용 시 데이터 오염 주의)

#### 파일 위치
- `internal/protocols/webrtc/outgoing_track.go`
- `internal/protocols/webrtc/incoming_track.go`

---

### 최적화 3: SRTP 암호화 최적화 ⭐⭐⭐ (우선순위: 중간)

#### 현재 상태
```
SHA1 해싱: 2.07s (5.34%)
AES 암호화: 0.39s (1.01%)
총: ~3.5s (9%)
```

#### 문제점
- HMAC-SHA1은 상대적으로 느림
- 하드웨어 가속이 제한적

#### 최적화 방법 A: 하드웨어 가속 확인
```go
// Pion SRTP가 이미 최적화되어 있을 가능성
// CPU의 AES-NI, SHA extension 활용 확인
```

#### 최적화 방법 B: GCM 모드 전환 (고급)
```go
// AES-GCM 사용 (더 빠른 하드웨어 가속)
// 하지만 Pion WebRTC 설정 변경 필요
// 클라이언트 호환성 확인 필요
```

#### 예상 효과
- **CPU**: -1~3% 절감 (이미 최적화되어 있을 가능성)

#### 구현 난이도: ⭐⭐⭐⭐ (어려움)
- Pion WebRTC 설정 깊이 파고들어야 함
- 클라이언트 호환성 이슈
- 위험도: 높음

#### 결정: **보류** (효과 대비 위험도 높음)

---

### 최적화 4: 불필요한 메모리 복사 제거 ⭐⭐ (우선순위: 중간)

#### 현재 상태
```
runtime.memmove: 0.56s (1.45%)
runtime.memclr: 0.55s (1.42%)
```

#### 최적화 방법
슬라이스 공유 및 재사용:
```go
// Before (복사)
newBuf := make([]byte, len(buf))
copy(newBuf, buf)

// After (공유)
newBuf := buf[:len(buf):len(buf)] // 용량 제한으로 안전하게 공유
```

#### 예상 효과
- **CPU**: -1~2% 절감

#### 구현 난이도: ⭐⭐⭐ (중간-어려움)
- 코드 전체 리뷰 필요
- 데이터 경쟁 조건 주의
- 위험도: 중간

---

### 최적화 5: 고루틴 풀 사용 ⭐⭐ (우선순위: 낮음)

#### 현재 상태
```
고루틴 수: 2,562개
runtime.futex: 0.85s (2.19%) - 고루틴 대기
```

#### 문제점
- 고루틴 생성/제거 오버헤드
- 스케줄링 오버헤드

#### 최적화 방법
워커 풀 패턴:
```go
type WorkerPool struct {
    tasks chan func()
    workers int
}

// 고루틴 재사용
```

#### 예상 효과
- **메모리**: -2~3 MB
- **CPU**: -1~2% 절감
- **고루틴 수**: 50% 감소 가능

#### 구현 난이도: ⭐⭐⭐⭐ (어려움)
- 아키텍처 변경 필요
- 기존 코드 대대적 수정
- 위험도: 높음

#### 결정: **보류** (효과 대비 위험도 높음)

---

### 최적화 6: 패킷 배치 처리 ⭐⭐⭐ (우선순위: 낮음, 고급)

#### 현재 상태
```
syscall.Syscall6: 13.90s (35.87%)
```
- 패킷마다 개별 시스템 콜

#### 문제점
- 시스템 콜 오버헤드가 가장 큼
- 커널-유저 공간 전환 비용

#### 최적화 방법
`sendmmsg()` 시스템 콜 사용:
```go
// 여러 패킷을 한 번에 전송
// Linux 3.0+ 지원
```

#### 예상 효과
- **CPU**: -10~15% 절감 (가장 큰 효과)

#### 구현 난이도: ⭐⭐⭐⭐⭐ (매우 어려움)
- Pion WebRTC 내부 깊이 수정
- net 패키지 수준 수정 필요
- 버퍼 관리 복잡
- 레이턴시 증가 가능
- 위험도: 매우 높음

#### 결정: **보류** (효과는 크지만 위험도 매우 높음)

---

## 최종 구현 계획

### Phase 1: 안전한 최적화 (즉시 적용)

#### 1-1. RTCP 간격 조정
- **파일**: `internal/protocols/webrtc/outgoing_track.go`
- **변경**: `Period: 1 * time.Second` → `Period: 3 * time.Second`
- **예상 효과**: CPU -3~5%
- **위험도**: 낮음 ✅

### Phase 2: 중간 최적화 (신중하게 적용)

#### 2-1. 버퍼 풀 적용
- **파일**:
  - `internal/protocols/webrtc/outgoing_track.go`
  - `internal/protocols/webrtc/incoming_track.go`
- **변경**: RTP 패킷 버퍼에 `sync.Pool` 적용
- **예상 효과**: CPU -2~3%
- **위험도**: 중간 ⚠️

#### 2-2. 불필요한 복사 제거
- **파일**: 프로파일 기반으로 핫스팟 파일 수정
- **변경**: 슬라이스 공유, 제로 카피 기법
- **예상 효과**: CPU -1~2%
- **위험도**: 중간 ⚠️

### Phase 3: 고급 최적화 (보류)

다음 최적화는 **위험도가 높아 현재 단계에서는 보류**:
- ❌ SRTP GCM 전환 (클라이언트 호환성)
- ❌ 고루틴 풀 (아키텍처 변경)
- ❌ 패킷 배치 처리 (Pion 라이브러리 수정)

---

## 구현 순서

### Step 1: RTCP 간격 조정 ✅
1. `outgoing_track.go` 찾기
2. RTCP Period 수정
3. 테스트 빌드

### Step 2: 버퍼 풀 적용 ✅
1. RTP 패킷 처리 코드 분석
2. `sync.Pool` 구현
3. 할당 핫스팟에 적용
4. 테스트 빌드

### Step 3: 메모리 복사 최적화 (선택적)
1. memmove 핫스팟 찾기
2. 제로 카피 적용 가능 여부 판단
3. 안전하다면 적용

### Step 4: 빌드 및 배포
1. Linux 바이너리 빌드
2. Docker 이미지 생성
3. .tar 파일 생성

### Step 5: 프로파일링 및 검증
1. 배포 후 프로파일 수집
2. 성능 개선 확인
3. 기능 정상 작동 확인

---

## 예상 총 효과

### 최소 예상 (Phase 1만)
- **CPU**: -3~5% 추가 절감
- **현재**: 21.5% → **16~18%**

### 최대 예상 (Phase 1 + 2)
- **CPU**: -6~10% 추가 절감
- **현재**: 21.5% → **11~15%**

### 누적 총 개선 (초기 대비)
| 항목 | 초기 | Phase 1 | Phase 1+2 |
|------|------|---------|-----------|
| 메모리 | 180 MB | 28 MB | 26 MB |
| CPU | 37.5% | 16~18% | 11~15% |
| 고루틴 | 3,654 | 2,562 | 2,562 |

**총 개선율**:
- 메모리: **-84~86%**
- CPU: **-52~60%** (Phase 1+2 완료 시)

---

## 위험 관리

### 각 최적화의 위험도

| 최적화 | 위험도 | 롤백 가능 | 테스트 필요도 |
|--------|--------|-----------|---------------|
| RTCP 간격 | 낮음 ✅ | 쉬움 | 낮음 |
| 버퍼 풀 | 중간 ⚠️ | 쉬움 | 중간 |
| 복사 제거 | 중간 ⚠️ | 쉬움 | 높음 |
| SRTP 변경 | 높음 ❌ | 어려움 | 매우 높음 |
| 고루틴 풀 | 높음 ❌ | 어려움 | 매우 높음 |
| 패킷 배치 | 매우 높음 ❌ | 어려움 | 매우 높음 |

### 검증 방법
1. **기능 테스트**: WebRTC 스트리밍 정상 작동
2. **성능 테스트**: CPU/메모리 프로파일링
3. **품질 테스트**: 비디오 품질, 패킷 손실률
4. **안정성 테스트**: 24시간 운영

---

## 권장 사항

### 즉시 적용 (안전)
1. ✅ **RTCP 간격 조정** (Phase 1-1)
   - 위험 낮음, 효과 확실

### 신중하게 적용 (중간 위험)
2. ⚠️ **버퍼 풀 사용** (Phase 2-1)
   - 테스트 후 적용
   - 메모리 릭 주의

### 보류 (높은 위험)
3. ❌ 고급 최적화들
   - 효과 대비 위험도 높음
   - 현재 성능으로 충분하다면 불필요

---

## 질문 사항

계획 진행 전 확인:

1. **Phase 1 (RTCP 간격)만 적용할까요? 아니면 Phase 2 (버퍼 풀)도 함께?**
   - Phase 1만: 안전하지만 적은 개선 (3-5%)
   - Phase 1+2: 더 큰 개선 (6-10%) 하지만 테스트 필요

2. **복사 제거 최적화도 시도할까요?**
   - 추가 1-2% 절감 가능
   - 코드 변경 많음

3. **배포 후 즉시 테스트 가능한가요?**
   - 기능 검증
   - 성능 측정

---

**계획 작성**: 2025-12-04
**현재 상태**: NACK + mDNS 제거 완료
**다음 단계**: Phase 1 또는 Phase 1+2 구현
